---
layout: project
title: Ethics Portfolio
image: /assets/images/boeing_737_max.png
render_with_liquid: true
---

# Ethical Decision-Making in Safety-Critical Aerospace Systems

## Introduction

Engineering decisions do not exist in isolation. They are shaped by technical constraints, organizational pressures, regulatory structures, and human judgment. Nowhere is this more evident than in safety-critical systems, where design tradeoffs can have irreversible consequences. This portfolio analyzes the ethical failures surrounding the Boeing 737 MAX Maneuvering Characteristics Augmentation System (MCAS) using a structured ethical framework developed across Weeks 6–9 of my engineering ethics coursework. By examining this case through material facts, stakeholder impacts, definitional ambiguities, ethical principles, and real-world constraints, I aim to demonstrate how ethical reasoning must be integrated into engineering practice, particularly in high-risk, high-stakes industries like aerospace.

## Identifying the Ethical Issues

The MCAS case presents multiple ethical issues spanning technical design, communication, and organizational responsibility. Central among these is whether it is ethically permissible to deploy a safety-critical system that relies on a single angle-of-attack (AoA) sensor, creating a single point of failure capable of overriding pilot inputs. Closely related is the ethical question of transparency: whether withholding detailed information about MCAS from pilots, airlines, and regulators violated engineers’ obligations to protect public safety.

Additional ethical concerns include the pressure to prioritize cost, schedule, and market competitiveness over robust safety margins; the adequacy of pilot training for new automated systems; and the responsibility of engineers to escalate safety concerns when organizational structures discourage dissent. These issues reflect classic conflicts between professional engineering duties and corporate or managerial incentives.

## Material, Individual, and Organizational Facts

From a technical standpoint, MCAS was designed to automatically command nose-down trim based on input from a single AoA sensor, without cross-checking redundant sensors. The system could activate repeatedly and with authority sufficient to overwhelm pilot inputs, while its existence and behavior were not clearly disclosed in pilot manuals or training materials. These design choices significantly increased vulnerability to sensor failure and pilot confusion.

At the individual level, engineers made design and classification decisions that labeled MCAS as non-safety-critical, allowing it to bypass more rigorous certification and redundancy requirements. Some engineers reportedly raised internal concerns, but these warnings were not effectively escalated or acted upon. Meanwhile, pilots were deprived of critical system knowledge needed to diagnose and respond to failures in real time.

Organizationally, Boeing’s corporate culture emphasized rapid development, cost containment, and minimal pilot retraining to maintain competitiveness with Airbus. The FAA’s delegation of certification authority to Boeing engineers further blurred lines of accountability, reducing independent oversight. Internal reporting channels were ineffective at elevating safety concerns, reinforcing a culture where commercial priorities outweighed ethical risk assessment.

## Definitional Clarification and Ethical Framing

A key insight from this analysis is how differing definitions of terms such as *safety*, *transparency*, *competence*, and *accountability* shape ethical judgment. Boeing’s operational definition of safety focused on regulatory compliance, while crash victims’ families understood safety as the proactive elimination of catastrophic risk. Similarly, Boeing treated transparency as meeting minimum disclosure requirements, whereas pilots and regulators expected full disclosure of system behavior affecting flight control.

These definitional gaps matter because ethical responsibility cannot be reduced to technical legality. When engineers define competence as simply meeting specifications rather than ensuring system robustness, ethically flawed decisions can appear justified. Ethical engineering requires adopting definitions grounded in public welfare, not organizational convenience.

## Ethical Principles and Conflict Resolution

Applying professional codes of ethics from ASME, NSPE, and similar organizations reveals clear conflicts between principles. The duty to “hold paramount the safety, health, and welfare of the public” directly conflicted with pressures to reduce cost, expedite certification, and minimize pilot training. In such conflicts, ethical hierarchies clearly place public safety above employer loyalty, schedule, or profit.

In the MCAS case, engineers should have refused certification of a single-sensor-dependent system, demanded redundancy, and ensured transparent communication to pilots. Ethical justification for these actions exists even if regulatory minimums were technically met, because professional engineering ethics require action beyond compliance when public safety is at risk.

## Practical Constraints and Prevention Strategies

While the ideal ethical response would have involved halting deployment until MCAS was redesigned, real-world constraints complicated decision-making. Organizational hierarchy discouraged dissent, regulatory ambiguity diluted responsibility, and engineers lacked full visibility into system-wide risk. These constraints do not excuse ethical failure but help explain how it occurred.

Preventing similar failures requires interventions at multiple levels. Individually, engineers must receive ethical training that emphasizes escalation and professional courage. Organizationally, companies must create psychologically safe reporting structures and decouple safety decisions from marketing objectives. Systemically, regulatory bodies must limit delegation of authority and strengthen independent oversight for safety-critical systems.

## Conclusion

The Boeing 737 MAX case demonstrates that ethical engineering is not merely about avoiding misconduct, but about actively safeguarding public welfare amid competing pressures. Technical excellence alone is insufficient without ethical judgment, transparency, and accountability. As a future mechanical engineer working on complex, safety-critical systems, this case reinforces my responsibility to prioritize human safety, question assumptions, and act ethically even when doing so is difficult. Engineering decisions shape real lives, and ethical integrity must be treated as a core design requirement, not an afterthought.